{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac42d6fe",
   "metadata": {},
   "source": [
    "# ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c35263",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35484934",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9049ec38-3469-44be-bc80-a4449bac12dd",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "871ccda1-aab6-46bb-867b-e16621babe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_file = 'retail_dw.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21fa299",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33d8d96-3cd9-4e7f-9567-37f95b6d9e5f",
   "metadata": {},
   "source": [
    "### DataFrame Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3118e477-33d7-4fe3-937b-a6d820cb999e",
   "metadata": {},
   "source": [
    "This logging offers a modularised way to print standardised logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2e3777b-a3ac-4615-8cb1-d6029e583695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_logger(df, stage_name):\n",
    "    \"\"\"\n",
    "    Log the number of rows in a dataframe\n",
    "    \"\"\"\n",
    "    print(f\"Stage: {stage_name} | Rows: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e4fb72-01a8-4b01-8f3e-1ff069e532db",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6981474-9b1d-401e-9d7c-892a4d7dc074",
   "metadata": {},
   "source": [
    "The dataset from the UCI ML website is the an Excel file that they claim has no null values. Thus, the dataset is imported using pandas `read_excel()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2b298be",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_xlsx_data(file):\n",
    "    \"\"\"\n",
    "    Load an Excel file into a Pandas Dataframe\n",
    "    \"\"\"\n",
    "    df = pd.read_excel(file)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386ea4fd-ec3a-48ee-8058-2e3195a0c7e8",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d42e2be-19ee-4d35-809a-79b1e9ec74ed",
   "metadata": {},
   "source": [
    "This involves:\n",
    "\n",
    "- Checking for null values\n",
    "- Checking for duplicates\n",
    "- Droping duplicates\n",
    "- Removing outliers\n",
    "- Datatype Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "336df6a9-db2a-465d-a5ba-3899db822ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_null_values(df):\n",
    "    \"\"\"\n",
    "    Check if null values exist in a Pandas Dataframe\n",
    "    \"\"\"\n",
    "    null_counts = df.isnull().sum()\n",
    "    null_counts = null_counts[null_counts > 0]\n",
    "    \n",
    "    if null_counts.empty:\n",
    "        print(\"No null values found in the dataframe.\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"Columns with null values:\")\n",
    "        for col, count in null_counts.items():\n",
    "            print(f\"{col}: {count}\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "523dcdc1-628b-477f-91b1-4bac435d7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates(df):\n",
    "    \"\"\"\n",
    "    Check if duplicates exist in a Pandas Dataframe\n",
    "    \"\"\"\n",
    "    duplicates = df.duplicated()\n",
    "    \n",
    "    if duplicates.any():\n",
    "        print(\"Duplicates found!\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"No duplicates found.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "562518ed-4ce5-4e7f-9ac3-bdce89387d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates(df):\n",
    "    \"\"\"\n",
    "    Drop duplicates in a Pandas DataFrame if they exist\n",
    "    \"\"\"\n",
    "    row_logger(df, \"Before dropping duplicates\")\n",
    "    \n",
    "    df_cleaned = df.drop_duplicates()\n",
    "    \n",
    "    row_logger(df_cleaned, \"After dropping duplicates\")\n",
    "    \n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a1596f9-a3ab-49c4-bca8-012b566939d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df):\n",
    "    \"\"\"\n",
    "    Remove numeric outliers: < 0 or <= 0\n",
    "    \"\"\"\n",
    "    row_logger(df, \"Before removing outliers\")\n",
    "    \n",
    "    outliers = df.copy()\n",
    "    \n",
    "    outliers = outliers[(outliers[\"Quantity\"] >= 0) & (outliers[\"UnitPrice\"] > 0)]\n",
    "\n",
    "    row_logger(outliers, \"After removing outliers\")\n",
    "\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "212720c4-6fbd-4c84-98bb-39844ba22324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datatype_conversion(df):\n",
    "    \"\"\"\n",
    "    Convert the columns in a Pandas Dataframe to the suitable datatype\n",
    "    \"\"\"\n",
    "    row_logger(df, \"Before datatype conversion\")\n",
    "    \n",
    "    converted = df.copy()\n",
    "\n",
    "    print(f\"These are the columns to convert:\\n\")\n",
    "    print(converted.columns.to_list())\n",
    "\n",
    "    converted[\"InvoiceNo\"] = converted[\"InvoiceNo\"].astype(str)\n",
    "    converted[\"StockCode\"] = converted[\"StockCode\"].astype(str)\n",
    "    converted[\"Description\"] = converted[\"Description\"].astype(str)\n",
    "    converted[\"Quantity\"] = pd.to_numeric(converted[\"Quantity\"], errors=\"coerce\").astype(\"Int64\")  # allows NaN\n",
    "    converted[\"InvoiceDate\"] = pd.to_datetime(converted[\"InvoiceDate\"], errors=\"coerce\")\n",
    "    converted[\"UnitPrice\"] = pd.to_numeric(converted[\"UnitPrice\"], errors=\"coerce\").astype(float)\n",
    "    converted[\"CustomerID\"] = converted[\"CustomerID\"].astype(str)\n",
    "    converted[\"Country\"] = converted[\"Country\"].astype(str)\n",
    "\n",
    "    print(converted.dtypes)\n",
    "\n",
    "    row_logger(converted, \"After datatype conversion\")\n",
    "\n",
    "    return converted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5fa09e-a9de-4f2e-a695-53f391327036",
   "metadata": {},
   "source": [
    "### Data Enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f4ae87-1071-42f3-9732-eb430c7bc5a7",
   "metadata": {},
   "source": [
    "This involves:\n",
    "\n",
    "- Creating a `TotalSales` column\n",
    "- Filtering for data from the last year of recorded data\n",
    "- Aggregating customer data into a summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bafbffb-a52a-4efb-8b3c-02b810c00481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_total_sales(df):\n",
    "    \"\"\"\n",
    "    Compute the total sales for each invoice transaction\n",
    "    \"\"\"\n",
    "    row_logger(df, \"Before creating TotalSales column\")\n",
    "    \n",
    "    total_sales = df.copy()\n",
    "    total_sales['TotalSales'] = total_sales['Quantity'] * total_sales['UnitPrice']\n",
    "\n",
    "    row_logger(total_sales, \"After creating TotalSales column\")\n",
    "\n",
    "    return total_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2230ba0-1bf0-4aba-acb1-c29df8a4b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_last_year(df):\n",
    "    \"\"\"\n",
    "    Filter the Pandas Dataframe to retain only transactions\n",
    "    from the last 365 days relative to the last date in the\n",
    "    Pandas Dataframe\n",
    "    \"\"\"\n",
    "    row_logger(df, \"Before filtering to the last year sales\")\n",
    "    \n",
    "    latest_date = df['InvoiceDate'].max()\n",
    "    one_year_ago = latest_date - timedelta(days=365)\n",
    "    \n",
    "    filtered = df[df[\"InvoiceDate\"] >= one_year_ago]\n",
    "\n",
    "    row_logger(filtered, \"After filtering to the last year sales\")\n",
    "    \n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfea058b-3f8f-4398-a3dd-bf7108b5b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_customer_summary(df):\n",
    "    \"\"\"\n",
    "    Aggregate customer data in order to obtain\n",
    "    customer summary metrics\n",
    "    \"\"\"\n",
    "    row_logger(df, \"Before aggregating customer data\")\n",
    "    \n",
    "    if 'CustomerID' not in df or 'TotalSales' not in df or 'Quantity' not in df or 'InvoiceDate' not in df:\n",
    "        raise ValueError(\"The DataFrame must contain 'CustomerID', 'TotalSales', 'Quantity', and 'InvoiceDate' columns.\")\n",
    "\n",
    "    customer_summary = df.groupby('CustomerID').agg(\n",
    "        total_sales=('TotalSales', 'sum'),\n",
    "        total_quantity=('Quantity', 'sum'),\n",
    "        avg_sales_per_transaction=('TotalSales', 'mean'),\n",
    "        num_transactions=('InvoiceNo', 'nunique'),  # Count distinct transactions\n",
    "        first_purchase_date=('InvoiceDate', 'min'),\n",
    "        last_purchase_date=('InvoiceDate', 'max')\n",
    "    ).reset_index()\n",
    "\n",
    "    row_logger(customer_summary, \"After aggregating customer data\")\n",
    "    \n",
    "    return customer_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebc3d3d-5842-472e-9faf-81dd5c49e474",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54a5142-afe4-4080-bd38-bcbd15c2633b",
   "metadata": {},
   "source": [
    "#### Creating Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56287a47-1680-41e1-b718-10b715e10b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection():\n",
    "    \"\"\"\n",
    "    Creates a connection to the SQLite database\n",
    "    \"\"\"\n",
    "    return sqlite3.connect(db_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc353b1-a734-4f95-8043-efe0b1c77927",
   "metadata": {},
   "source": [
    "#### Creating Database Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bbabb4-c60f-4b64-8a05-0405a3734d47",
   "metadata": {},
   "source": [
    "The star schema tables are modelled after the star schema below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c26296-7c3f-4a95-98dd-67a54e038398",
   "metadata": {},
   "source": [
    "![](../design/star_schema_design.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62598a33-a4d8-4b48-89dd-85c9f642c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_customer_dimension_table():\n",
    "    \"\"\"\n",
    "    Creates the Customer Dimension table in SQLite\n",
    "    \"\"\"\n",
    "    conn = create_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS customer_dimension (\n",
    "        CustomerID TEXT PRIMARY KEY,\n",
    "        Country TEXT\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c01b53c-6f5c-476b-b49a-0aed753b87d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sales_fact_table():\n",
    "    \"\"\"\n",
    "    Creates the Sales Fact table in SQLite\n",
    "    \"\"\"\n",
    "    conn = create_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS sales_fact (\n",
    "        InvoiceNo TEXT PRIMARY KEY,\n",
    "        CustomerID TEXT,\n",
    "        StockCode TEXT,               \n",
    "        Quantity INTEGER,\n",
    "        UnitPrice REAL,\n",
    "        TotalSales REAL,\n",
    "        InvoiceDate TEXT,\n",
    "        FOREIGN KEY (CustomerID) REFERENCES customer_dimension(CustomerID),\n",
    "        FOREIGN KEY (StockCode) REFERENCES product_dimension(StockCode)  -- Link to product dimension\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46366b38-f7ee-48aa-8e3b-294cb0e66a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_dimension_table():\n",
    "    \"\"\"\n",
    "    Creates the Date Dimension table in SQLite\n",
    "    \"\"\"\n",
    "    conn = create_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS date_dimension (\n",
    "        Date TEXT PRIMARY KEY,\n",
    "        Year INTEGER,\n",
    "        Month INTEGER,\n",
    "        Day INTEGER,\n",
    "        Weekday INTEGER,\n",
    "        Quarter INTEGER\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2607389c-86b1-4eac-8325-e449f7632ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_product_dimension_table():\n",
    "    \"\"\"\n",
    "    Creates the Product Dimension table in SQLite\n",
    "    \"\"\"\n",
    "    conn = create_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS product_dimension (\n",
    "        StockCode TEXT PRIMARY KEY,\n",
    "        Description TEXT\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4b9b00-dab9-4c5e-b3ba-11fd66e47d7d",
   "metadata": {},
   "source": [
    "#### Inserting Data into the Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e80534c-58fb-47fe-9bdf-93889fee22a8",
   "metadata": {},
   "source": [
    "Using the full dataframe dimensionality reduction is done to map the data onto each dimension and fact table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a21c05ef-7e02-49a0-868f-487bbd2b52ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_customer_dimension_data(df):\n",
    "    \"\"\"\n",
    "    Inserts data into the Customer Dimension table\n",
    "    \"\"\"\n",
    "    conn = create_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Insert the customer dimension data\n",
    "    customer_dim = df[['CustomerID', 'Country']].drop_duplicates()\n",
    "\n",
    "    row_logger(customer_dim, \"Inserting customer dimension data\")\n",
    "    \n",
    "    for _, row in customer_dim.iterrows():\n",
    "        cursor.execute('''\n",
    "        INSERT OR REPLACE INTO customer_dimension (CustomerID, Country)\n",
    "        VALUES (?, ?)\n",
    "        ''', (row['CustomerID'], row['Country']))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "115d91b3-3303-473a-a7df-7fbc48900ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_sales_fact_data(df):\n",
    "    \"\"\"\n",
    "    Inserts data into the Sales Fact table\n",
    "    \"\"\"\n",
    "    conn = create_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Insert sales fact data\n",
    "    df['TotalSales'] = df['Quantity'] * df['UnitPrice']  # Calculate TotalSales\n",
    "    \n",
    "    # We assume the 'StockCode' column is in the dataframe and needs to be inserted.\n",
    "    sales_fact = df[['InvoiceNo', 'CustomerID', 'StockCode', 'Quantity', 'UnitPrice', 'TotalSales', 'InvoiceDate']]\n",
    "\n",
    "    row_logger(sales_fact, \"Inserting sales fact data\")\n",
    "    \n",
    "    for _, row in sales_fact.iterrows():\n",
    "        cursor.execute('''\n",
    "        INSERT OR REPLACE INTO sales_fact (InvoiceNo, CustomerID, StockCode, Quantity, UnitPrice, TotalSales, InvoiceDate)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "        ''', (\n",
    "            row['InvoiceNo'], \n",
    "            row['CustomerID'], \n",
    "            row['StockCode'],  # Insert StockCode\n",
    "            row['Quantity'], \n",
    "            row['UnitPrice'], \n",
    "            row['TotalSales'], \n",
    "            row['InvoiceDate'].strftime('%Y-%m-%d')  # Ensure the date is formatted as 'YYYY-MM-DD'\n",
    "        ))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc8cfcb0-b070-4f25-892c-9903d526093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_date_dimension_data(df):\n",
    "    \"\"\"\n",
    "    Inserts data into the Date Dimension table\n",
    "    \"\"\"\n",
    "    conn = create_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Extract date parts and create date dimension\n",
    "    date_dim = pd.DataFrame()\n",
    "    date_dim['Date'] = df['InvoiceDate'].dt.date\n",
    "    date_dim['Year'] = df['InvoiceDate'].dt.year\n",
    "    date_dim['Month'] = df['InvoiceDate'].dt.month\n",
    "    date_dim['Day'] = df['InvoiceDate'].dt.day\n",
    "    date_dim['Weekday'] = df['InvoiceDate'].dt.weekday\n",
    "    date_dim['Quarter'] = df['InvoiceDate'].dt.quarter\n",
    "    \n",
    "    date_dim = date_dim.drop_duplicates()\n",
    "\n",
    "    row_logger(date_dim, \"Inserting date dimension data\")\n",
    "\n",
    "    for _, row in date_dim.iterrows():\n",
    "        cursor.execute('''\n",
    "        INSERT OR REPLACE INTO date_dimension (Date, Year, Month, Day, Weekday, Quarter)\n",
    "        VALUES (?, ?, ?, ?, ?, ?)\n",
    "        ''', (row['Date'], row['Year'], row['Month'], row['Day'], row['Weekday'], row['Quarter']))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80014b9b-7b17-405c-9fe3-f51be4988535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_product_dimension_data(df):\n",
    "    \"\"\"\n",
    "    Inserts data into the Product Dimension table\n",
    "    \"\"\"\n",
    "    conn = create_connection()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Insert product dimension data\n",
    "    product_dim = df[['StockCode', 'Description']].drop_duplicates()\n",
    "\n",
    "    row_logger(product_dim, \"Inserting product dimension data\")\n",
    "    \n",
    "    for _, row in product_dim.iterrows():\n",
    "        cursor.execute('''\n",
    "        INSERT OR REPLACE INTO product_dimension (StockCode, Description)\n",
    "        VALUES (?, ?)\n",
    "        ''', (row['StockCode'], row['Description']))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6d5637-41d3-4f75-8582-349d76b376d6",
   "metadata": {},
   "source": [
    "#### Retrieving Data from a Database Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41f5ca0c-c9dc-4811-a5e3-d3949e3187b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_first_five_rows(table_name):\n",
    "    \"\"\"\n",
    "    Fetches the first five rows from any table\n",
    "    \"\"\"\n",
    "    conn = create_connection()\n",
    "    query = f'SELECT * FROM {table_name} LIMIT 5'\n",
    "    result = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803a00f0-eed6-43a9-836d-f0ba0e810a71",
   "metadata": {},
   "source": [
    "#### Loading and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc7b331c-df68-44e8-8b32-58d84086e283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_verify_data(df):\n",
    "    \"\"\"\n",
    "    Creates the star schema tables\n",
    "    Inserts data into the star schema tables\n",
    "    Fetches and displays the first five rows for every one of the tables\n",
    "    \"\"\"\n",
    "    create_customer_dimension_table()\n",
    "    create_sales_fact_table()\n",
    "    create_date_dimension_table()\n",
    "    create_product_dimension_table()\n",
    "\n",
    "    insert_customer_dimension_data(df)\n",
    "    insert_sales_fact_data(df)\n",
    "    insert_date_dimension_data(df)\n",
    "    insert_product_dimension_data(df)\n",
    "\n",
    "    print(\"First 5 rows of Customer Dimension Table:\")\n",
    "    print(fetch_first_five_rows('customer_dimension'))\n",
    "    \n",
    "    print(\"\\nFirst 5 rows of Sales Fact Table:\")\n",
    "    print(fetch_first_five_rows('sales_fact'))\n",
    "    \n",
    "    print(\"\\nFirst 5 rows of Date Dimension Table:\")\n",
    "    print(fetch_first_five_rows('date_dimension'))\n",
    "    \n",
    "    print(\"\\nFirst 5 rows of Product Dimension Table:\")\n",
    "    print(fetch_first_five_rows('product_dimension'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e50a93-52f3-4df8-b06a-9cf284899a14",
   "metadata": {},
   "source": [
    "## ETL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f1725aa2-0663-4dd2-9a41-ce0639818f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_pipeline():\n",
    "    \"\"\"\n",
    "    Extract\n",
    "    \"\"\"\n",
    "    # Load the Excel file into the raw dataframe\n",
    "    raw_df = load_xlsx_data(\"../../data/raw/Online Retail.xlsx\")\n",
    "\n",
    "    # Display the first five rows of the raw dataframea\n",
    "    raw_df.head(5)\n",
    "\n",
    "    \"\"\"\n",
    "    Transform\n",
    "    \"\"\"\n",
    "\n",
    "    # Perform datatype conversion for all the columns in the dataframe\n",
    "    df_converted = datatype_conversion(raw_df)\n",
    "\n",
    "    # Original Intent: Filter sales data to the last year assuming that the day is August 12 2025\n",
    "    # This is done immediately after datatype conversion since\n",
    "    # 1. Only this data will be saved to the database\n",
    "    # 2. It will minimise computational complexity\n",
    "    # 3. The last year is the time range of interest\n",
    "    # The functionality of the filter_last_year() function has been modified\n",
    "    # It filters for the last year starting at the last InvoiceDate\n",
    "    # This is done because there is no data from August 12 2024 to August 12 2025\n",
    "    # Actual Intent: Filter sales data for the last year starting at the last InvoiceDate\n",
    "    df_filtered = filter_last_year(df_converted)\n",
    "\n",
    "    # Check for missing values to cross validate the UCI ML statistics\n",
    "    # There should be no missing values\n",
    "    check_null_values(df_filtered)\n",
    "    \n",
    "    # Handle duplicates by dropping them if they exist\n",
    "    if check_duplicates(df_filtered):\n",
    "        df_no_duplicates = drop_duplicates(df_filtered)\n",
    "    else:\n",
    "        df_no_duplicates = df_filtered\n",
    "\n",
    "    # Handle outliers in the Quantity and UnitPrice columns\n",
    "    df_no_outliers = remove_outliers(df_no_duplicates)\n",
    "\n",
    "    # Compute the TotalSales Column\n",
    "    df_revenue = create_total_sales(df_no_outliers)\n",
    "\n",
    "    # Group data by the CustomerID\n",
    "    df_customer = aggregate_customer_summary(df_revenue)\n",
    "\n",
    "    # Display the first five rows of the customer aggregated summary dataframe\n",
    "    df_customer.head(5)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Load\n",
    "    \"\"\"\n",
    "\n",
    "    # Load and verify the loading to database\n",
    "    load_and_verify_data(df_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b31b6bb3-a19b-4f3b-9e47-8270b305848a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc903cc306ab47bea357f370d0d31d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<div style='font-family: monospace; color: #333;'>[2025-08-13 21:32:23]  Stage: → **Before datatyp…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the columns to convert:\n",
      "\n",
      "['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']\n",
      "InvoiceNo              object\n",
      "StockCode              object\n",
      "Description            object\n",
      "Quantity                Int64\n",
      "InvoiceDate    datetime64[ns]\n",
      "UnitPrice             float64\n",
      "CustomerID             object\n",
      "Country                object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "905035284ced49f5a7fd83af8d5abfbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<div style='font-family: monospace; color: #333;'>[2025-08-13 21:32:24]  Stage: → **After datatype…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "390bea5cc4fc40e79219152892872ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<div style='font-family: monospace; color: #333;'>[2025-08-13 21:32:24]  Stage: → **Before filteri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97652b59347c4d4aa66a1bace73cd66c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<div style='font-family: monospace; color: #333;'>[2025-08-13 21:32:24]  Stage: → **After filterin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No null values found in the dataframe.\n",
      "Duplicates found!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f23a19a8414a7c9730041834310694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<div style='font-family: monospace; color: #333;'>[2025-08-13 21:32:24]  Stage: → **Before droppin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "731399e25c0544e58e53c877222f733f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<div style='font-family: monospace; color: #333;'>[2025-08-13 21:32:25]  Stage: → **After dropping…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d008ba891de940ffa072d051c85e42c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<div style='font-family: monospace; color: #333;'>[2025-08-13 21:32:25]  Stage: → **Before removin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29eaf5fa28a84f1c9c5378b522e391a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<div style='font-family: monospace; color: #333;'>[2025-08-13 21:32:25]  Stage: → **After removing…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ea49f6f20a4402a2da189f86906954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<div style='font-family: monospace; color: #333;'>[2025-08-13 21:32:25]  Stage: → **Before creatin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3fc4bfa4ca4e9090e651f130fa1c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<div style='font-family: monospace; color: #333;'>[2025-08-13 21:32:25]  Stage: → **After creating…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed9fa48149349eda0d26185c0d067ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<div style='font-family: monospace; color: #333;'>[2025-08-13 21:32:25]  Stage: → **Before aggrega…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05620434a81844ddbdf11a2c45347c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<div style='font-family: monospace; color: #333;'>[2025-08-13 21:32:25]  Stage: → **After aggregat…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bc48aa1489c4e3895dc0b0e72a756ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<div style='font-family: monospace; color: #333;'>[2025-08-13 21:32:25]  Stage: → **Inserting cust…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7b6427d2ee45b1ac481935d187ca17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<div style='font-family: monospace; color: #333;'>[2025-08-13 21:32:25]  Stage: → **Inserting sale…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e178090f8f0428bb187bf7f44f4b7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<div style='font-family: monospace; color: #333;'>[2025-08-13 21:32:49]  Stage: → **Inserting date…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2348/1137704813.py:22: DeprecationWarning: The default date adapter is deprecated as of Python 3.12; see the sqlite3 documentation for suggested replacement recipes\n",
      "  cursor.execute('''\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c26d79bbaa1e42e3b4ed9d7e710f1f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<div style='font-family: monospace; color: #333;'>[2025-08-13 21:32:49]  Stage: → **Inserting prod…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of Customer Dimension Table:\n",
      "  CustomerID         Country\n",
      "0    14479.0  United Kingdom\n",
      "1    16065.0  United Kingdom\n",
      "2    17430.0  United Kingdom\n",
      "3    16520.0  United Kingdom\n",
      "4    15945.0  United Kingdom\n",
      "\n",
      "First 5 rows of Sales Fact Table:\n",
      "  InvoiceNo CustomerID StockCode  Quantity  UnitPrice  TotalSales InvoiceDate\n",
      "0    538032    14479.0     22696         6       1.95       11.70  2010-12-09\n",
      "1    538035    16065.0     22175         5       2.95       14.75  2010-12-09\n",
      "2    538037    17430.0     71477        12       3.25       39.00  2010-12-09\n",
      "3    538040    16520.0     20685         1       7.95        7.95  2010-12-09\n",
      "4    538044        nan     22812         1       1.95        1.95  2010-12-09\n",
      "\n",
      "First 5 rows of Date Dimension Table:\n",
      "         Date  Year  Month  Day  Weekday  Quarter\n",
      "0  2010-12-09  2010     12    9        3        4\n",
      "1  2010-12-10  2010     12   10        4        4\n",
      "2  2010-12-12  2010     12   12        6        4\n",
      "3  2010-12-13  2010     12   13        0        4\n",
      "4  2010-12-14  2010     12   14        1        4\n",
      "\n",
      "First 5 rows of Product Dimension Table:\n",
      "  StockCode                 Description\n",
      "0     22669           RED BABY BUNTING \n",
      "1     22465  HANGING METAL STAR LANTERN\n",
      "2     22727   ALARM CLOCK BAKELIKE RED \n",
      "3     22726  ALARM CLOCK BAKELIKE GREEN\n",
      "4     22840  ROUND CAKE TIN VINTAGE RED\n"
     ]
    }
   ],
   "source": [
    "etl_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
